{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Part 2: PCA Method with Maximum Likelihood Estimation (MLE)\n",
                "\n",
                "---\n",
                "\n",
                "**Name:** Arwa Ahmed Mostafa Shazly  \n",
                "**ID:** 221100209  \n",
                "\n",
                "---"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 23,
            "metadata": {},
            "outputs": [],
            "source": [
                "import numpy as np\n",
                "import pandas as pd\n",
                "from scipy import linalg\n",
                "import warnings\n",
                "warnings.filterwarnings('ignore')\n",
                "np.random.seed(42)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Load and Prepare Data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 24,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Original: 20,000,263 ratings\n",
                        "Scale: 1 to 5\n"
                    ]
                }
            ],
            "source": [
                "ratings_df = pd.read_csv('ratings.csv')\n",
                "print(f\"Original: {len(ratings_df):,} ratings\")\n",
                "orig_min, orig_max = ratings_df['rating'].min(), ratings_df['rating'].max()\n",
                "ratings_df['rating'] = (ratings_df['rating'] - orig_min) / (orig_max - orig_min) * 4 + 1\n",
                "print(f\"Scale: 1 to 5\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 40,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Filtered sample: 142,888 ratings, 14,201 users, 800 items\n"
                    ]
                }
            ],
            "source": [
                "# Filter data (Random Sample)\n",
                "user_counts = ratings_df['userId'].value_counts()\n",
                "item_counts = ratings_df['movieId'].value_counts()\n",
                "\n",
                "valid_items = item_counts[item_counts >= 20].index.tolist()\n",
                "valid_users = user_counts[user_counts >= 20].index.tolist()\n",
                "\n",
                "np.random.seed(42)\n",
                "sample_items = set(np.random.choice(valid_items, size=800, replace=False))\n",
                "sample_items.add(2)\n",
                "sample_items.add(8860)\n",
                "sample_users = set(np.random.choice(valid_users, size=15000, replace=False))\n",
                "\n",
                "filtered_df = ratings_df[\n",
                "    (ratings_df['userId'].isin(sample_users)) & \n",
                "    (ratings_df['movieId'].isin(sample_items))\n",
                "]\n",
                "\n",
                "print(f\"Filtered sample: {len(filtered_df):,} ratings, {filtered_df['userId'].nunique():,} users, {filtered_df['movieId'].nunique()} items\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 26,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Rating Matrix: (14201, 796)\n"
                    ]
                }
            ],
            "source": [
                "I1 = 2\n",
                "I2 = 8860\n",
                "\n",
                "def train_test_split_per_user(df, test_ratio=0.2, seed=42):\n",
                "    np.random.seed(seed)\n",
                "    train_list, test_list = [], []\n",
                "    for uid, udata in df.groupby('userId'):\n",
                "        n = len(udata)\n",
                "        if n < 5:\n",
                "            train_list.append(udata)\n",
                "            continue\n",
                "        shuffled = udata.sample(frac=1, random_state=seed)\n",
                "        n_test = max(1, int(n * test_ratio))\n",
                "        test_list.append(shuffled.iloc[:n_test])\n",
                "        train_list.append(shuffled.iloc[n_test:])\n",
                "    return pd.concat(train_list), pd.concat(test_list)\n",
                "\n",
                "train_df, test_df = train_test_split_per_user(filtered_df)\n",
                "rating_matrix = train_df.pivot_table(index='userId', columns='movieId', values='rating')\n",
                "print(f\"Rating Matrix: {rating_matrix.shape}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "# Point 1: MLE-based Covariance Matrix\n",
                "\n",
                "- Step 1: Compute item means using only observed ratings\n",
                "- Step 2: Center the data around item means\n",
                "- Step 3: Form products of deviations\n",
                "- Step 4: Estimate covariances using only co-rated entries"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 41,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Covariance matrix shape: (796, 796)\n",
                        "Symmetric: True \n"
                    ]
                }
            ],
            "source": [
                "def compute_mle_covariance_matrix(rating_matrix):\n",
                "    data = rating_matrix.values.astype(np.float32)\n",
                "    items = rating_matrix.columns\n",
                "    mask = ~np.isnan(data) \n",
                "    \n",
                "    # STEP 1: Compute item means using only observed ratings\n",
                "    # For each product, average only over users who have specified ratings\n",
                "    means = np.nanmean(data, axis=0)\n",
                "    \n",
                "    # STEP 2: Center the data around item means\n",
                "    # X_i = P1_i - mean(P1), Y_i = P2_i - mean(P2)\n",
                "    centered = np.where(mask, data - means, 0).astype(np.float32)\n",
                "    \n",
                "    # STEP 3: Form products of deviations, (X_i)(Y_i) for each pair of items\n",
                "    products_sum = centered.T @ centered\n",
                "    \n",
                "    # STEP 4: Divide by (n-1) co-rated users, cov(A,B) = Sum / (n_AB - 1)\n",
                "    # Only users who rated BOTH items contribute\n",
                "    co_rated_counts = mask.astype(np.float32).T @ mask.astype(np.float32)\n",
                "    denominator = np.maximum(co_rated_counts - 1, 1)\n",
                "    cov_matrix = np.divide(products_sum, denominator, \n",
                "                           out=np.zeros_like(products_sum), \n",
                "                           where=co_rated_counts > 1)\n",
                "    \n",
                "    return pd.DataFrame(cov_matrix, index=items, columns=items)\n",
                "\n",
                "cov_matrix = compute_mle_covariance_matrix(rating_matrix)\n",
                "print(f\"\\nCovariance matrix shape: {cov_matrix.shape}\")\n",
                "print(f\"Symmetric: {np.allclose(cov_matrix.values, cov_matrix.values.T)} \")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "# Point 2: Top Peers\n",
                "Using the MLE covariance matrix, select items with highest covariance to target."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 42,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Top 5 peers for I1 (movieId=2):\n",
                        "movieId\n",
                        "26887    3.6066\n",
                        "106      2.0141\n",
                        "6956     1.4735\n",
                        "1922     1.4254\n",
                        "6177     1.2812\n",
                        "Name: 2, dtype: float32\n",
                        "\n",
                        "Top 5 peers for I2 (movieId=8860):\n",
                        "movieId\n",
                        "6978      4.3112\n",
                        "581       4.2948\n",
                        "8650      3.5571\n",
                        "103688    3.3277\n",
                        "5815      2.8036\n",
                        "Name: 8860, dtype: float32\n"
                    ]
                }
            ],
            "source": [
                "def get_top_peers(cov_matrix, target_item, k):\n",
                "    return cov_matrix[target_item].drop(target_item).nlargest(k)\n",
                "\n",
                "top5_I1 = get_top_peers(cov_matrix, I1, 5)\n",
                "top5_I2 = get_top_peers(cov_matrix, I2, 5)\n",
                "top10_I1 = get_top_peers(cov_matrix, I1, 10)\n",
                "top10_I2 = get_top_peers(cov_matrix, I2, 10)\n",
                "\n",
                "print(f\"\\nTop 5 peers for I1 (movieId={I1}):\")\n",
                "print(top5_I1.round(4))\n",
                "print(f\"\\nTop 5 peers for I2 (movieId={I2}):\")\n",
                "print(top5_I2.round(4))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "# Points 3-4: PCA with 5 Peers\n",
                "1. Compute eigenvalues λ and eigenvectors p of Σ_MLE: det(Σ - λI) = 0\n",
                "2. Center data and project users into latent space: t_i = x_i · p\n",
                "3. Reconstruct missing ratings: r̂ = mean + t · p^T"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 43,
            "metadata": {},
            "outputs": [],
            "source": [
                "def pca_predict_with_steps(rating_matrix, target_item, peers, var_thresh=0.9):\n",
                "    items = [target_item] + list(peers.index)\n",
                "    submatrix = rating_matrix[items]\n",
                "    item_means = submatrix.mean()\n",
                "    filled = submatrix.fillna(item_means)\n",
                "    \n",
                "    # PCA STEP 1: Center the data, X'_i = P1_i - mean(P1)\n",
                "    centered = filled - item_means\n",
                "    # Covariance of submatrix\n",
                "    cov = np.cov(centered.T)\n",
                "    \n",
                "    # PCA STEP 2: Eigendecomposition\n",
                "    # det(Σ - λI) = 0\n",
                "    # Get eigenvalues (λ) and eigenvectors (p)\n",
                "    eigenvalues, eigenvectors = linalg.eigh(cov)\n",
                "    \n",
                "    # Sort by eigenvalue (descending)\n",
                "    idx = np.argsort(eigenvalues)[::-1]\n",
                "    eigenvalues = eigenvalues[idx]\n",
                "    eigenvectors = eigenvectors[:, idx]\n",
                "    \n",
                "    # PCA STEP 3: Select components (90% variance threshold)\n",
                "    # Fraction of total variance = λ_k / Σλ\n",
                "    cumvar = np.cumsum(eigenvalues) / eigenvalues.sum()\n",
                "    n_comp = max(1, np.argmax(cumvar >= var_thresh) + 1)\n",
                "    n_comp = min(n_comp, len(items))\n",
                "    \n",
                "    # Principal components (eigenvectors for selected components)\n",
                "    pc = eigenvectors[:, :n_comp]\n",
                "    \n",
                "    # PCA STEP 4: Project users into latent space\n",
                "    # t_i = x_i · p (user score on PC)\n",
                "    # This gives the LATENT FACTORS\n",
                "    latent = centered.values @ pc\n",
                "    latent_df = pd.DataFrame(latent, index=rating_matrix.index,\n",
                "                             columns=[f'PC{i+1}' for i in range(n_comp)])\n",
                "    \n",
                "    # PCA STEP 5: Reconstruct missing ratings\n",
                "    # r̂_i = mean + t_i · p^T\n",
                "    reconstructed = latent @ pc.T + item_means.values\n",
                "    \n",
                "    # Prediction for target item (first column)\n",
                "    predictions = pd.Series(reconstructed[:, 0], index=rating_matrix.index).clip(1, 5)\n",
                "    return predictions, eigenvalues, eigenvectors, n_comp, items, latent_df"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 44,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "PCA RESULTS FOR I1 (movieId=2) WITH 5 PEERS\n",
                        "\n",
                        "Items in submatrix: [2, 26887, 106, 6956, 1922, 6177]\n",
                        "\n",
                        "EIGENVALUES (λ):\n",
                        "Values: [0.0644 0.0025 0.0016 0.0016 0.0005 0.0004]\n",
                        "Variance %: [90.8  3.5  2.2  2.2  0.7  0.6]\n",
                        "Cumulative %: [ 90.8  94.3  96.5  98.7  99.4 100. ]\n",
                        "\n",
                        "EIGENVECTORS (Principal Components p):\n",
                        "          PC1     PC2     PC3     PC4     PC5     PC6\n",
                        "2      1.0000  0.0033  0.0031 -0.0037 -0.0027  0.0013\n",
                        "26887  0.0040  0.0009 -0.9545  0.2982  0.0006 -0.0003\n",
                        "106    0.0023 -0.9584 -0.0761 -0.2405  0.0010  0.1333\n",
                        "6956   0.0016 -0.1218 -0.0177 -0.0573  0.0413 -0.9899\n",
                        "1922   0.0032 -0.2579  0.2873  0.9205 -0.0520 -0.0288\n",
                        "6177   0.0028 -0.0074  0.0164  0.0504  0.9978  0.0394\n",
                        "\n",
                        "Components selected: 1 (for 90% variance threshold)\n",
                        "First PC (p1): [1.     0.004  0.0023 0.0016 0.0032 0.0028]\n",
                        "\n",
                        "LATENT FACTORS (t_i = x_i · p), First 5 Users\n",
                        "           PC1\n",
                        "userId        \n",
                        "11      0.0008\n",
                        "12      0.0000\n",
                        "21      0.0000\n",
                        "33      0.0000\n",
                        "34     -0.2498\n"
                    ]
                }
            ],
            "source": [
                "# I1 with 5 peers\n",
                "pred_I1_5, eigenvals_I1, eigenvecs_I1, n_comp_I1, items_I1, latent_I1 = pca_predict_with_steps(\n",
                "    rating_matrix, I1, top5_I1\n",
                ")\n",
                "\n",
                "print(f\"PCA RESULTS FOR I1 (movieId={I1}) WITH 5 PEERS\")\n",
                "print(f\"\\nItems in submatrix: {items_I1}\")\n",
                "\n",
                "print(f\"\\nEIGENVALUES (λ):\")\n",
                "print(f\"Values: {eigenvals_I1.round(4)}\")\n",
                "print(f\"Variance %: {(eigenvals_I1/eigenvals_I1.sum()*100).round(1)}\")\n",
                "print(f\"Cumulative %: {(np.cumsum(eigenvals_I1)/eigenvals_I1.sum()*100).round(1)}\")\n",
                "\n",
                "print(f\"\\nEIGENVECTORS (Principal Components p):\")\n",
                "eigenvec_df = pd.DataFrame(eigenvecs_I1, index=items_I1,\n",
                "                           columns=[f'PC{i+1}' for i in range(len(items_I1))])\n",
                "print(eigenvec_df.round(4))\n",
                "\n",
                "print(f\"\\nComponents selected: {n_comp_I1} (for 90% variance threshold)\")\n",
                "print(f\"First PC (p1): {eigenvecs_I1[:, 0].round(4)}\")\n",
                "\n",
                "print(f\"\\nLATENT FACTORS (t_i = x_i · p), First 5 Users\")\n",
                "print(latent_I1.head(5).round(4))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 45,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "PCA RESULTS FOR I2 (movieId=8860) WITH 5 PEERS\n",
                        "\n",
                        "EIGENVALUES (λ):\n",
                        "Values: [0.0079 0.0049 0.0024 0.0016 0.0009 0.0007]\n",
                        "Variance %: [43.  26.7 13.   8.5  4.9  3.9]\n",
                        "\n",
                        ":EIGENVECTORS (p):\n",
                        "           PC1     PC2     PC3     PC4     PC5     PC6\n",
                        "8860   -0.1054  0.9777 -0.1242  0.0685  0.1074  0.0374\n",
                        "6978   -0.0035  0.1225  0.9565 -0.0344 -0.0782  0.2506\n",
                        "581    -0.9932 -0.1096  0.0105 -0.0056  0.0359  0.0099\n",
                        "8650   -0.0164  0.0703  0.2410  0.0029 -0.0422 -0.9669\n",
                        "103688 -0.0039  0.0681 -0.0457 -0.9958 -0.0388 -0.0076\n",
                        "5815   -0.0464  0.0868 -0.0973  0.0489 -0.9888  0.0262\n",
                        "\n",
                        "Components selected: 4\n",
                        "\n",
                        "LATENT FACTORS (First 5 Users)\n",
                        "        PC1  PC2  PC3  PC4\n",
                        "userId                    \n",
                        "11      0.0  0.0  0.0  0.0\n",
                        "12      0.0  0.0  0.0  0.0\n",
                        "21      0.0  0.0  0.0  0.0\n",
                        "33      0.0  0.0  0.0  0.0\n",
                        "34      0.0  0.0  0.0  0.0\n"
                    ]
                }
            ],
            "source": [
                "# I2 with 5 peers\n",
                "pred_I2_5, eigenvals_I2, eigenvecs_I2, n_comp_I2, items_I2, latent_I2 = pca_predict_with_steps(\n",
                "    rating_matrix, I2, top5_I2\n",
                ")\n",
                "\n",
                "print(f\"PCA RESULTS FOR I2 (movieId={I2}) WITH 5 PEERS\")\n",
                "print(f\"\\nEIGENVALUES (λ):\")\n",
                "print(f\"Values: {eigenvals_I2.round(4)}\")\n",
                "print(f\"Variance %: {(eigenvals_I2/eigenvals_I2.sum()*100).round(1)}\")\n",
                "\n",
                "print(f\"\\n:EIGENVECTORS (p):\")\n",
                "eigenvec_df_I2 = pd.DataFrame(eigenvecs_I2, index=items_I2,\n",
                "                              columns=[f'PC{i+1}' for i in range(len(items_I2))])\n",
                "print(eigenvec_df_I2.round(4))\n",
                "\n",
                "print(f\"\\nComponents selected: {n_comp_I2}\")\n",
                "\n",
                "print(f\"\\nLATENT FACTORS (First 5 Users)\")\n",
                "print(latent_I2.head(5).round(4))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## Points 5-6: PCA with 10 Peers"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 33,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "10 Peers - I1: 4 components\n",
                        "10 Peers - I2: 8 components\n"
                    ]
                }
            ],
            "source": [
                "pred_I1_10, eigenvals_I1_10, _, n_comp_I1_10, _, latent_I1_10 = pca_predict_with_steps(\n",
                "    rating_matrix, I1, top10_I1\n",
                ")\n",
                "pred_I2_10, eigenvals_I2_10, _, n_comp_I2_10, _, latent_I2_10 = pca_predict_with_steps(\n",
                "    rating_matrix, I2, top10_I2\n",
                ")\n",
                "print(f\"10 Peers - I1: {n_comp_I1_10} components\")\n",
                "print(f\"10 Peers - I2: {n_comp_I2_10} components\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## Latent Factors Comparison: 5 vs 10 Peers"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 46,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "LATENT FACTORS (First 10 Users)\n",
                        "\n",
                        "I1 with 5 PEERS\n",
                        "           PC1\n",
                        "userId        \n",
                        "11      0.0008\n",
                        "12      0.0000\n",
                        "21      0.0000\n",
                        "33      0.0000\n",
                        "34     -0.2498\n",
                        "40      0.0000\n",
                        "41      0.0000\n",
                        "46      0.0000\n",
                        "56      0.0000\n",
                        "66      0.0000\n",
                        "\n",
                        "I1 with 10 PEERS\n",
                        "           PC1     PC2     PC3     PC4\n",
                        "userId                                \n",
                        "11      0.0008  0.0002  0.0008 -0.1838\n",
                        "12      0.0000  0.0000  0.0000  0.0000\n",
                        "21      0.0000  0.0000  0.0000  0.0000\n",
                        "33      0.0000  0.0000  0.0000  0.0000\n",
                        "34     -0.2498 -0.0008 -0.0008 -0.0014\n",
                        "40      0.0000  0.0000  0.0000  0.0000\n",
                        "41      0.0000  0.0000  0.0000  0.0000\n",
                        "46      0.0000  0.0000  0.0000  0.0000\n",
                        "56      0.0000  0.0000  0.0000  0.0000\n",
                        "66      0.0000  0.0000  0.0000  0.0000\n"
                    ]
                }
            ],
            "source": [
                "print(\"LATENT FACTORS (First 10 Users)\")\n",
                "print(f\"\\nI1 with 5 PEERS\")\n",
                "print(latent_I1.head(10).round(4))\n",
                "print(f\"\\nI1 with 10 PEERS\")\n",
                "print(latent_I1_10.head(10).round(4))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## Predicted Ratings for Missing Values\n",
                "\n",
                "Show first 10 users who had MISSING ratings for the target item, and their predicted values."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 47,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "PREDICTED RATINGS FOR ORIGINALLY MISSING VALUES\n",
                        "\n",
                        "I1 (movieId=2)\n",
                        "Total users with missing I1 rating: 12,888\n",
                        "\n",
                        "First 10 users and their PREDICTED ratings:\n",
                        "\n",
                        "5 PEERS predictions:\n",
                        "  User 11: predicted = 3.473\n",
                        "  User 12: predicted = 3.472\n",
                        "  User 21: predicted = 3.472\n",
                        "  User 33: predicted = 3.472\n",
                        "  User 40: predicted = 3.472\n",
                        "  User 41: predicted = 3.472\n",
                        "  User 46: predicted = 3.472\n",
                        "  User 56: predicted = 3.472\n",
                        "  User 66: predicted = 3.472\n",
                        "  User 71: predicted = 3.472\n",
                        "\n",
                        "10 PEERS predictions:\n",
                        "  User 11: predicted = 3.472\n",
                        "  User 12: predicted = 3.472\n",
                        "  User 21: predicted = 3.472\n",
                        "  User 33: predicted = 3.472\n",
                        "  User 40: predicted = 3.472\n",
                        "  User 41: predicted = 3.472\n",
                        "  User 46: predicted = 3.472\n",
                        "  User 56: predicted = 3.472\n",
                        "  User 66: predicted = 3.472\n",
                        "  User 71: predicted = 3.472\n",
                        "\n",
                        "I2 (movieId=8860)\n",
                        "Total users with missing I2 rating: 14,100\n",
                        "\n",
                        "First 10 users and their PREDICTED ratings:\n",
                        "\n",
                        "5 PEERS predictions:\n",
                        "  User 11: predicted = 3.376\n",
                        "  User 12: predicted = 3.376\n",
                        "  User 21: predicted = 3.376\n",
                        "  User 33: predicted = 3.376\n",
                        "  User 34: predicted = 3.376\n",
                        "  User 40: predicted = 3.376\n",
                        "  User 41: predicted = 3.376\n",
                        "  User 46: predicted = 3.376\n",
                        "  User 56: predicted = 3.376\n",
                        "  User 66: predicted = 3.376\n"
                    ]
                }
            ],
            "source": [
                "print(\"PREDICTED RATINGS FOR ORIGINALLY MISSING VALUES\")\n",
                "# Users who had MISSING rating for I1\n",
                "missing_I1 = rating_matrix[I1].isna()\n",
                "users_missing_I1 = missing_I1[missing_I1].index[:10]  # First 10\n",
                "\n",
                "print(f\"\\nI1 (movieId={I1})\")\n",
                "print(f\"Total users with missing I1 rating: {missing_I1.sum():,}\")\n",
                "print(f\"\\nFirst 10 users and their PREDICTED ratings:\")\n",
                "print(\"\\n5 PEERS predictions:\")\n",
                "for user in users_missing_I1:\n",
                "    print(f\"  User {user}: predicted = {pred_I1_5[user]:.3f}\")\n",
                "\n",
                "print(\"\\n10 PEERS predictions:\")\n",
                "for user in users_missing_I1:\n",
                "    print(f\"  User {user}: predicted = {pred_I1_10[user]:.3f}\")\n",
                "\n",
                "# Users who had MISSING rating for I2\n",
                "missing_I2 = rating_matrix[I2].isna()\n",
                "users_missing_I2 = missing_I2[missing_I2].index[:10]\n",
                "\n",
                "print(f\"\\nI2 (movieId={I2})\")\n",
                "print(f\"Total users with missing I2 rating: {missing_I2.sum():,}\")\n",
                "print(f\"\\nFirst 10 users and their PREDICTED ratings:\")\n",
                "print(\"\\n5 PEERS predictions:\")\n",
                "for user in users_missing_I2:\n",
                "    print(f\"  User {user}: predicted = {pred_I2_5[user]:.3f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## Evaluation: MAE and RMSE"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 48,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "EVALUATION RESULTS\n",
                        "5 Peers - I1: MAE=0.6657, RMSE=0.8517\n",
                        "5 Peers - I2: MAE=0.5945, RMSE=0.7370\n",
                        "10 Peers - I1: MAE=0.6657, RMSE=0.8518\n",
                        "10 Peers - I2: MAE=0.5945, RMSE=0.7368\n"
                    ]
                }
            ],
            "source": [
                "def compute_mae(preds, test_df, item):\n",
                "    subset = test_df[test_df['movieId'] == item]\n",
                "    errors = [abs(row['rating'] - preds[row['userId']]) \n",
                "              for _, row in subset.iterrows() if row['userId'] in preds.index]\n",
                "    return np.mean(errors) if errors else np.nan\n",
                "\n",
                "def compute_rmse(preds, test_df, item):\n",
                "    subset = test_df[test_df['movieId'] == item]\n",
                "    errors = [(row['rating'] - preds[row['userId']])**2 \n",
                "              for _, row in subset.iterrows() if row['userId'] in preds.index]\n",
                "    return np.sqrt(np.mean(errors)) if errors else np.nan\n",
                "\n",
                "mae_I1_5 = compute_mae(pred_I1_5, test_df, I1)\n",
                "rmse_I1_5 = compute_rmse(pred_I1_5, test_df, I1)\n",
                "mae_I2_5 = compute_mae(pred_I2_5, test_df, I2)\n",
                "rmse_I2_5 = compute_rmse(pred_I2_5, test_df, I2)\n",
                "mae_I1_10 = compute_mae(pred_I1_10, test_df, I1)\n",
                "rmse_I1_10 = compute_rmse(pred_I1_10, test_df, I1)\n",
                "mae_I2_10 = compute_mae(pred_I2_10, test_df, I2)\n",
                "rmse_I2_10 = compute_rmse(pred_I2_10, test_df, I2)\n",
                "\n",
                "print(\"EVALUATION RESULTS\")\n",
                "print(f\"5 Peers - I1: MAE={mae_I1_5:.4f}, RMSE={rmse_I1_5:.4f}\")\n",
                "print(f\"5 Peers - I2: MAE={mae_I2_5:.4f}, RMSE={rmse_I2_5:.4f}\")\n",
                "print(f\"10 Peers - I1: MAE={mae_I1_10:.4f}, RMSE={rmse_I1_10:.4f}\")\n",
                "print(f\"10 Peers - I2: MAE={mae_I2_10:.4f}, RMSE={rmse_I2_10:.4f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## Point 7: Compare 5 vs 10 Peers"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 49,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Item  Peers  Components    MAE   RMSE\n",
                        "  I1      5           1 0.6657 0.8517\n",
                        "  I1     10           4 0.6657 0.8518\n",
                        "  I2      5           4 0.5945 0.7370\n",
                        "  I2     10           8 0.5945 0.7368\n"
                    ]
                }
            ],
            "source": [
                "comparison = pd.DataFrame({\n",
                "    'Item': ['I1', 'I1', 'I2', 'I2'],\n",
                "    'Peers': [5, 10, 5, 10],\n",
                "    'Components': [n_comp_I1, n_comp_I1_10, n_comp_I2, n_comp_I2_10],\n",
                "    'MAE': [mae_I1_5, mae_I1_10, mae_I2_5, mae_I2_10],\n",
                "    'RMSE': [rmse_I1_5, rmse_I1_10, rmse_I2_5, rmse_I2_10]\n",
                "})\n",
                "print(comparison.round(4).to_string(index=False))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## Points 8-9: Part 1 vs Part 2"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 38,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Part 1 (Mean-Filling): predictions ~2.916 (uniform)\n",
                        "Part 2 (MLE): I1 mean=3.472, std=0.000\n",
                        "Part 2 (MLE): I2 mean=3.376, std=0.003\n"
                    ]
                }
            ],
            "source": [
                "print(\"Part 1 (Mean-Filling): predictions ~2.916 (uniform)\")\n",
                "print(f\"Part 2 (MLE): I1 mean={pred_I1_5[missing_I1].mean():.3f}, std={pred_I1_5[missing_I1].std():.3f}\")\n",
                "print(f\"Part 2 (MLE): I2 mean={pred_I2_5[missing_I2].mean():.3f}, std={pred_I2_5[missing_I2].std():.3f}\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.8.10"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
